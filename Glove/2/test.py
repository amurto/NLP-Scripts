# -*- coding: utf-8 -*-
"""hstest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r6_GKKju6U80i3VUIwdozBgjyIyiFgtl
"""

from google.colab import drive
drive.mount('/content/drive')

'''
Testing Script
'''
import json
import pickle
import numpy as np
from keras.preprocessing.sequence import pad_sequences
from keras.models import load_model
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import pandas as pd

MAX_SENTENCE_LENGTH = 70

data = pd.read_csv("/content/drive/My Drive/Hate Speech Detection/Training/Datasets/hsfinal.csv")

text_data = data["Comment"].tolist()
text_labels = data["Hate"].tolist()

# Split dataset in training and test.
X_train, X_test, y_train, y_test = train_test_split(text_data, text_labels, test_size=0.1, random_state=0)

# initialize the encoder
encoder = LabelEncoder()
encoder.fit(y_train)

# loading tokenizer for polarity model
with open('/content/drive/My Drive/Hate Speech Detection/Production/Models/tokenhater.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

# loading the polarity model
hatespeech_model = load_model('/content/drive/My Drive/Hate Speech Detection/Production/Models/hate_model.h5')

# Tokenize
sequences_test = tokenizer.texts_to_sequences(X_test)

# Padding to make all the texts of same length
test_data = pad_sequences(sequences_test, maxlen=MAX_SENTENCE_LENGTH)

data['Hate'].value_counts()

# Both the tasks should have same dimensions of inputs
if(len(y_test) % 2 != 0):
    y_test = y_test[:-1]
    test_data = test_data[:-1]

# Task-1 training data and labels
t1_y_test = y_test[0:int(len(y_test)/2)]
t1_x_test = test_data[0:int(len(y_test)/2)]

# Task-2 training data and labels
t2_y_test = y_test[int(len(y_test)/2):]
t2_x_test = test_data[int(len(y_test)/2):]

y_pred_combined = hatespeech_model.predict([t1_x_test, t2_x_test])
t1_y_pred = np.argmax(y_pred_combined[0], axis=-1)
t2_y_pred = np.argmax(y_pred_combined[1], axis=-1)

t1_y_pred = encoder.inverse_transform(t1_y_pred)
t2_y_pred = encoder.inverse_transform(t2_y_pred)

# Detect hatespeech in sentences
while True:
    predictions = {}
    query1 = str(input('Please enter the text: '))
    print(query1)
    # Tokenize
    sequences_test = tokenizer.texts_to_sequences([query1])
    
    # Padding to make all the texts of same length
    test_data = pad_sequences(sequences_test, maxlen=MAX_SENTENCE_LENGTH)
    
    t1_x_test = test_data
    t2_x_test = test_data
    
    y_pred_combined = hatespeech_model.predict([t1_x_test, t2_x_test])
    y_pred_proba = y_pred_combined[0]

    y_pred = np.argmax(y_pred_proba, axis=-1)
    y_pred = encoder.inverse_transform(y_pred)

    print(f"Prediction :{y_pred}")
    px = y_pred_proba[0].tolist()
    for i in range(0, len(px)):
      print(encoder.inverse_transform([i])[0]," : ",px[i])
    
    predictions['Text Input'] = query1
    predictions['Probabilities'] = y_pred_proba.tolist()
    predictions['Label'] = y_pred.tolist()
    with open('result.json', 'a') as fp:
        json.dump(predictions, fp, indent=4)