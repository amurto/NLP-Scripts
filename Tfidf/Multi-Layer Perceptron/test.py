# -*- coding: utf-8 -*-
"""ed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HgqBBbxR2gs46CpuuIIqqXu6dP82Au-F
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd 
import numpy as np
from sklearn.linear_model import LogisticRegression
df=pd.read_csv("/content/drive/My Drive/Entity Disambiguation/Training Folder/ner_dataset.csv",encoding='latin1')

from sklearn.model_selection import train_test_split

x_df=df['Word']
y_df=df['Tag']
X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, random_state=0)

import pickle
from sklearn.externals import joblib
from sklearn.feature_extraction.text import TfidfVectorizer

vect = TfidfVectorizer(min_df=5).fit(X_train)

filename2 = '/content/drive/My Drive/Entity Disambiguation/Production Folder/Models/mpl_model.sav'

loaded_model2 = joblib.load(filename2)
result2 = loaded_model2.predict(vect.transform(['hi']))
#result2[0]

import nltk
nltk.download("punkt")

from nltk.tokenize import sent_tokenize, word_tokenize 
import warnings 

warnings.filterwarnings(action = 'ignore') 

import gensim 
from gensim.models import Word2Vec 

sample = open("/content/drive/My Drive/Entity Disambiguation/Production Folder/Models/ncorpus.txt", "r") 
s = sample.read() 

# Replaces escape character with space 
f = s.replace("\n", " ") 

data = [] 

# iterate through each sentence in the file 
for i in sent_tokenize(f): 
	temp = [] 
	
	# tokenize the sentence into words 
	for j in word_tokenize(i): 
		temp.append(j.lower()) 

	data.append(temp)

modell= Word2Vec.load("/content/drive/My Drive/Entity Disambiguation/Production Folder/Models/cbow.model")



def test():
  phrase=input("Enter a sentence : ")
  phrase = phrase.lower()
  phrase = word_tokenize(phrase)
  l1=[]
  l2=[]
  l3=[]
  entity = []
  entity_dict = {}
  for p in phrase:
    x = loaded_model2.predict(vect.transform([p]))
    if x[0] != 'O':
      entity.append(p)

  for d in entity:
    b = []
    a = modell.similar_by_word(d, topn=10, restrict_vocab=None)
    for i in a:
      x = loaded_model2.predict(vect.transform([i[0]]))[0][-3:]
      y = loaded_model2.predict(vect.transform([d]))[0][-3:]
      if x == y:
        b.append(i)  
    entity_dict[d] = {'entity': loaded_model2.predict(vect.transform([d]))[0], 'similar_entities': b }

  print(entity_dict)

  # import JSONEncoder class from json
  from json.encoder import JSONEncoder
  # directly called encode method of JSON
  JSONEncoder().encode(entity_dict)

test()