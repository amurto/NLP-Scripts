# -*- coding: utf-8 -*-
"""toxic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hd60tjRhTRN0wo5TbhlP9fzp8xnoEU43
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd, numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

train = pd.read_csv('/content/drive/My Drive/datasets/hatekeyword.csv')
test = pd.read_csv('/content/drive/My Drive/datasets/toxic/test.csv')
subm = pd.read_csv('/content/drive/My Drive/datasets/toxic/sample_submission.csv')

train.head()

train['comment_text'][0]

label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
train['none'] = 1-train[label_cols].max(axis=1)
train.describe()

COMMENT = 'comment_text'
train[COMMENT].fillna("unknown", inplace=True)
test[COMMENT].fillna("unknown", inplace=True)

import re, string
re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')
def tokenize(s): return re_tok.sub(r' \1 ', s).split()

n = train.shape[0]
vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,
               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,
               smooth_idf=1, sublinear_tf=1 )
trn_term_doc = vec.fit_transform(train[COMMENT])
test_term_doc = vec.transform(test[COMMENT])

import pickle
# Dump the file
pickle.dump(vec, open("hatewords.pkl", "wb"))

vect = pickle.load(open("/content/drive/My Drive/Keyword_Suggestion/Production/Models/hatewords.pkl", 'rb'))

vec.vocabulary_

trn_term_doc, test_term_doc

from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.utils.validation import check_X_y, check_is_fitted
from sklearn.linear_model import LogisticRegression
from scipy import sparse
class NbSvmClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, C=1.0, dual=False, n_jobs=1):
        self.C = C
        self.dual = dual
        self.n_jobs = n_jobs

    def predict(self, x):
        # Verify that model has been fit
        check_is_fitted(self, ['_r', '_clf'])
        return self._clf.predict(x.multiply(self._r))

    def predict_proba(self, x):
        # Verify that model has been fit
        check_is_fitted(self, ['_r', '_clf'])
        return self._clf.predict_proba(x.multiply(self._r))

    def fit(self, x, y):
        # Check that X and y have correct shape
        y = y.values
        x, y = check_X_y(x, y, accept_sparse=True)

        def pr(x, y_i, y):
            p = x[y==y_i].sum(0)
            return (p+1) / ((y==y_i).sum()+1)

        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))
        x_nb = x.multiply(self._r)
        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)
        return self

model = NbSvmClassifier(C=4, dual=True, n_jobs=-1).fit(trn_term_doc, train['negative'])

model

from sklearn.externals import joblib 
  
# Save the model as a pickle in a file 
joblib.dump(model, 'kw_model.pkl') 
  
# Load the model from the file 
mdl = joblib.load('kw_model.pkl')

predictions = mdl.predict(test_term_doc)

# Testing some data
text_list = ["hate","sex","i LIKE YOU","you are a good guy"]

df = pd.DataFrame(text_list, columns =['COMMENT'])

hate = vec.transform(df['COMMENT'])

df

predictions1 = mdl.predict(hate)

predictions1