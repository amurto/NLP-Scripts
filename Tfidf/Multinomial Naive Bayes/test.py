# -*- coding: utf-8 -*-
"""kstest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qg9xAVXUcu3G9RZuGGzaLfL2uTu7heOR
"""

from google.colab import drive
drive.mount('/content/drive')

pip install vaderSentiment

import pandas as pd, numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import json

import nltk
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('tagsets')

import re, string
re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')
def tokenize(s): return re_tok.sub(r' \1 ', s).split()

from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.utils.validation import check_X_y, check_is_fitted
from sklearn.linear_model import LogisticRegression
from scipy import sparse
class NbSvmClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, C=1.0, dual=False, n_jobs=1):
        self.C = C
        self.dual = dual
        self.n_jobs = n_jobs

    def predict(self, x):
        # Verify that model has been fit
        check_is_fitted(self, ['_r', '_clf'])
        return self._clf.predict(x.multiply(self._r))

    def predict_proba(self, x):
        # Verify that model has been fit
        check_is_fitted(self, ['_r', '_clf'])
        return self._clf.predict_proba(x.multiply(self._r))

    def fit(self, x, y):
        # Check that X and y have correct shape
        y = y.values
        x, y = check_X_y(x, y, accept_sparse=True)

        def pr(x, y_i, y):
            p = x[y==y_i].sum(0)
            return (p+1) / ((y==y_i).sum()+1)

        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))
        x_nb = x.multiply(self._r)
        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)
        return self

import pickle
from sklearn.externals import joblib 
# hate_word_embeddings = joblib.load("/content/drive/My Drive/Keyword_Suggestion/Production/Models/hatewords.pkl")

hate_word_embeddings = pickle.load(open("/content/drive/My Drive/Keyword_Suggestion/Production/Models/hatewords.pkl", 'rb'))

# Load the model from the file 
model = joblib.load("/content/drive/My Drive/Keyword_Suggestion/Production/Models/kw_model.pkl")

# import SentimentIntensityAnalyzer class 
# from vaderSentiment.vaderSentiment module. 
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from nltk.tokenize import word_tokenize
from nltk.stem.wordnet import WordNetLemmatizer
wnl = WordNetLemmatizer()
import random
import re
import pandas as pd
import nltk 
from nltk.corpus import wordnet

inc_posug = [
      'absolutely',
     'completely',
     'fairly',
     'quite',
      'totally',
      'utterly',
      'perfectly',
      'entirely',
      'practically',
      'kind of',
       'really'
]

inc_posg = [
            'too',
      'very',
      'extremely',
      'really'       
]

dec_posg = [
            'slightly',
      'a bit',
      'quite',
       'a little',
       'marginally'
]

inc_negug = [
      'frightfully',
      'awfully',
      'terribly',
      'absolutely',
      'completely',
       'utterly',
       'entirely',
       'practically',
       'somewhat',
       'kind of',
       'really'         
]

inc_negg = [
             'too',
      'very',
      'extremely',
      'really'   
]

dec_negg = [
            'slightly',
      'a bit',
      'quite',
       'a little',
       'marginally'          
]

# Check whether an adective is gradable or ungradable
def is_gradable_adj(word):
  if nltk.pos_tag([re.sub('$', 'est', word)])[0][1] == 'JJS':
    return True
  else:
    return False

def get_first_char(x):
  return x[0]

# Check whether a word is a downtoner or not
def is_downtoner(word):
  word = word.lower()
  if word in dec_posg or word in dec_negg:
    return True
  else:
    return False

# Calculate sentiment polarity of a sentence
def sentiment_scores(sentence):
  sid_obj = SentimentIntensityAnalyzer()
  sentiment_dict = sid_obj.polarity_scores(sentence)
  score = sentiment_dict['compound']
  return score

# Use the model to check if a word is toxic or not
def is_hate(word):
  h = hate_word_embeddings.transform([word])
  p = model.predict(h)
  if p[0] == 1:
    return True
  else: 
    return False

# Get similar words for toxic words
def get_keywords(word): 
  word = word.lower()
  synonyms = [] 
  s = sentiment_scores(word)
  print(s)
  for syn in wordnet.synsets(word): 
    for l in syn.lemmas(): 
      synonyms.append(l.name())
  
  x = list(set(synonyms))
  keywords = []

  for i in x:
    if nltk.pos_tag(i)[0][1] == nltk.pos_tag(word)[0][1]:
      # print(i)
      # print(sentiment_scores(i))
      if sentiment_scores(i) > s:
        keywords.append(i)
  return keywords

def increase_pol(df, pol):
  suggestions = {}

  #### increasing positivity ###
  if pol > 0.05:
    for i in range(1, len(df)):
      # Finding superlative of gradable adjectives
      if df['tag'].iloc[i] == 'JJ':
        w = df['token'].iloc[i]
        if nltk.pos_tag([re.sub('$', 'est', w)])[0][1] == 'JJS':
          if w in suggestions.keys():
            suggestions[w].append(re.sub('$', 'est', w))
          else:
            suggestions[w] = [re.sub('$', 'est', w)]

    #Checking for already present degree modifiers
    for i in range(1, len(df)):
      # Dont find keywords for superlative adjectives
      if df['tag'].iloc[i] != 'JJS':
        if get_first_char(df['tag'].iloc[i]) == 'J':
          # Check if word before adjective is an adverb
          if is_gradable_adj(df['token'].iloc[i]):
              dmod = inc_posg
          else:
              dmod = inc_posug
              cap = df['token'].iloc[i]
              if cap in suggestions.keys():
                suggestions[cap].append(cap.upper() + "!")
              else:
                suggestions[cap] = [cap.upper() + "!"]
    
          if get_first_char(df['tag'].iloc[i-1]) == 'R':
            if is_downtoner(df['token'].iloc[i-1]):
              suggestions[df['token'].iloc[i-1] + " " + df['token'].iloc[i]] = [df['token'].iloc[i]]
            
            random.shuffle(dmod)
            rj = df['token'].iloc[i-1] + " " + df['token'].iloc[i]
            ri = df['token'].iloc[i]
            mods = dmod[1:3]
            rjnew = [s + " " + ri for s in mods]
            if rj in suggestions.keys():
              suggestions[rj].append(rjnew)
            else:
              suggestions[rj] = rjnew
          else:
            random.shuffle(dmod)
            rj = df['token'].iloc[i]
            mods = dmod[1:3]
            rjnew = [s + " " + rj for s in mods]
            if rj in suggestions.keys():
              suggestions[rj].append(rjnew)
            else:
              suggestions[rj] = rjnew
          
      

    

    # print(suggestions)

  #### decreasing negativity ###
  elif pol < -0.05:
    # print("negative")

    
    
    # Find superlative and degrade to positive
    df['s1'] = ""
    for i in range(1, len(df)):
      # print(df['tag'].iloc[i])
      if df['tag'].iloc[i] == 'JJS':
        adj = wnl.lemmatize(df['token'].iloc[i], 'a')
        if df['token'].iloc[i] != adj:
          w = df['token'].iloc[i]
          if w in suggestions.keys():
            suggestions[w].append(adj)
          else:
            suggestions[w] = [adj]
      
      # Using downtoners to reduce intensity
      else:
        if get_first_char(df['tag'].iloc[i]) == 'J':
          if get_first_char(df['tag'].iloc[i-1]) == 'R':
            if not is_downtoner(df['token'].iloc[i-1]):
              ad = df['token'].iloc[i-1] + " " + df['token'].iloc[i]
              if ad in suggestions.keys(): 
                suggestions[ad].append(df['token'].iloc[i])
              else:
                suggestions[ad] = [df['token'].iloc[i]]
          else:
            if is_gradable_adj(df['token'].iloc[i]):
              dmod = dec_posg
              random.shuffle(dmod)
              mods = dmod[1:3]
              kw = df['token'].iloc[i]
              kwnew = [s + " " + kw for s in mods]
              if kw in suggestions.keys():
                suggestions[kw].append(kwnew)
              else:
                suggestions[kw] = kwnew
            else:
              dmod = dec_posg
              random.shuffle(dmod)
              mods = dmod[1:3]
              kw = df['token'].iloc[i]
              kwnew = [s + " " + kw for s in mods]
              if kw in suggestions.keys():
                suggestions[kw].append(kwnew)
              else:
                suggestions[kw] = kwnew
     


   
    # print(df)
    # print(suggestions)
  else:
    for i in range(1, len(df)):
      # Intensification of words by capitalization and exclamation marks
      if get_first_char(df['tag'].iloc[i]) == "J":
        k = df['token'].iloc[i].upper() + "!"
        if df['token'].iloc[i] in suggestions.keys():
          suggestions[df['token'].iloc[i]].append(k)
        else:
          suggestions[df['token'].iloc[i]] = [k]



      # Using degree modifiers with adjectives to increase intensity
      if df['tag'].iloc[i] != "JJS":
        if get_first_char(df['tag'].iloc[i]) == "J":
          if is_gradable_adj(df['token'].iloc[i]):
            kw = [re.sub('$', 'est', df['token'].iloc[i])]
            if df['token'].iloc[i] in suggestions.keys():
              suggestions[df['token'].iloc[i]].append(kw)
            else:
              suggestions[df['token'].iloc[i]] = [kw]
          else:
            dmod = inc_posug
            random.shuffle(dmod)
            mods = dmod[1:3]
            adj = df['token'].iloc[i] 
            kw = [s + " " + adj for s in mods]
            if adj in suggestions.keys():
              suggestions[adj].append(kw)
            else:
              suggestions[adj] = kw
    # print(suggestions)    
    # print("neutral")

  return suggestions

def decrease_pol(df, pol):
  suggestions = {}

  #### decreasing positivity ###
  if pol > 0.05:
    # print("positive")

 # Find superlative and degrade to positive
    df['s1'] = ""
    for i in range(1, len(df)):
      # print(df['tag'].iloc[i])
      if df['tag'].iloc[i] == 'JJS':
        adj = wnl.lemmatize(df['token'].iloc[i], 'a')
        if df['token'].iloc[i] != adj:
          w = df['token'].iloc[i]
          if w in suggestions.keys():
            suggestions[w].append(adj)
          else:
            suggestions[w] = [adj]
      # Using downtoners to reduce intensity
      else:
        if get_first_char(df['tag'].iloc[i]) == 'J':
          if get_first_char(df['tag'].iloc[i-1]) == 'R':
            if not is_downtoner(df['token'].iloc[i-1]):
              ad = df['token'].iloc[i-1] + " " + df['token'].iloc[i]
              if ad in suggestions.keys(): 
                suggestions[ad].append(df['token'].iloc[i])
              else:
                suggestions[ad] = [df['token'].iloc[i]]
          else:
            if is_gradable_adj(df['token'].iloc[i]):
              dmod = dec_posg
              random.shuffle(dmod)
              mods = dmod[1:3]
              kw = df['token'].iloc[i]
              kwnew = [s + " " + kw for s in mods]
              if kw in suggestions.keys():
                suggestions[kw].append(kwnew)
              else:
                suggestions[kw] = kwnew
            else:
              dmod = dec_posg
              random.shuffle(dmod)
              mods = dmod[1:3]
              kw = df['token'].iloc[i]
              kwnew = [s + " " + kw for s in mods]
              if kw in suggestions.keys():
                suggestions[kw].append(kwnew)
              else:
                suggestions[kw] = kwnew
     



    # print(suggestions)
    # print(df)

  #### increasing negativity ###
  elif pol < -0.05:
    # print("negative")
    for i in range(1, len(df)):
      # Finding superlative of gradable adjectives
      if df['tag'].iloc[i] == 'JJ':
        w = df['token'].iloc[i]
        if nltk.pos_tag([re.sub('$', 'est', w)])[0][1] == 'JJS':
          if w in suggestions.keys():
            suggestions[w].append(re.sub('$', 'est', w))
          else:
            suggestions[w] = [re.sub('$', 'est', w)]

    #Checking for already present degree modifiers
    for i in range(1, len(df)):
      # Dont find keywords for superlative adjectives
      if df['tag'].iloc[i] != 'JJS':
        if get_first_char(df['tag'].iloc[i]) == 'J':
          # Check if word before adjective is an adverb
          if is_gradable_adj(df['token'].iloc[i]):
              dmod = inc_negg
          else:
              dmod = inc_negug
              cap = df['token'].iloc[i]
              if cap in suggestions.keys():
                suggestions[cap].append(cap.upper() + "!")
              else:
                suggestions[cap] = [cap.upper() + "!"]
    
          if get_first_char(df['tag'].iloc[i-1]) == 'R':
            if is_downtoner(df['token'].iloc[i-1]):
              suggestions[df['token'].iloc[i-1] + " " + df['token'].iloc[i]] = [df['token'].iloc[i]]
            # Randomly select three degree modifiers
            random.shuffle(dmod)
            rj = df['token'].iloc[i-1] + " " + df['token'].iloc[i]
            ri = df['token'].iloc[i]
            mods = dmod[1:3]
            rjnew = [s + " " + ri for s in mods]
            if rj in suggestions.keys():
              suggestions[rj].append(rjnew)
            else:
              suggestions[rj] = rjnew
          else:
            random.shuffle(dmod)
            rj = df['token'].iloc[i]
            mods = dmod[1:3]
            rjnew = [s + " " + rj for s in mods]
            if rj in suggestions.keys():
              suggestions[rj].append(rjnew)
            else:
              suggestions[rj] = rjnew
          
      

    

    # print(suggestions)
  else:
    for i in range(1, len(df)):
      # Intensification of words by capitalization and exclamation marks
      if get_first_char(df['tag'].iloc[i]) == "J":
        k = df['token'].iloc[i].upper() + "!"
        if df['token'].iloc[i] in suggestions.keys():
          suggestions[df['token'].iloc[i]].append(k)
        else:
          suggestions[df['token'].iloc[i]] = [k]



      # Using degree modifiers with adjectives to increase intensity
      if df['tag'].iloc[i] != "JJS":
        if get_first_char(df['tag'].iloc[i]) == "J":
          if is_gradable_adj(df['token'].iloc[i]):
            kw = [re.sub('$', 'est', df['token'].iloc[i])]
            if df['token'].iloc[i] in suggestions.keys():
              suggestions[df['token'].iloc[i]].append(kw)
            else:
              suggestions[df['token'].iloc[i]] = [kw]
          else:
            dmod = inc_posug
            random.shuffle(dmod)
            mods = dmod[1:3]
            adj = df['token'].iloc[i] 
            kw = [s + " " + adj for s in mods]
            if adj in suggestions.keys():
              suggestions[adj].append(kw)
            else:
              suggestions[adj] = kw

        
    # print("neutral")

  return suggestions

def calculate_sentiment(text, opt):
  pol = sentiment_scores(text)
  print("Sentiment polarity of sentence: ",pol)
  tokens = word_tokenize(text)
  tupletags = nltk.pos_tag(tokens)
  tree = []
  for i in tupletags:
    tree.append(list(i))
  for t in tree:
    t.append(sentiment_scores(t[0]))
  df = pd.DataFrame(tree, columns =['token', 'tag', 'score'])
  new_row = pd.DataFrame({'token': '*s#', 'tag': '*s#', 'score': 2}, 
                                                            index =[0]) 
  # simply concatenate both dataframes 
  df = pd.concat([new_row, df]).reset_index(drop = True)
  
  # print(df)
  if opt == 1:
    suggestions = increase_pol(df, pol)
  else:
    suggestions = decrease_pol(df, pol)
  
  if opt == 1:
    if pol < -0.05:
      for i in range(1, len(df)):
        if is_hate(df['token'].iloc[i]):
          w = df['token'].iloc[i]
          syns = get_keywords(w)
          if w in suggestions.keys():
            suggestions[w].append(syns)
          else:
            suggestions[w] = syns

  # print(suggestions)
  js = json.dumps(suggestions)
  print(js)

def test():
  print("Enter text")
  text = input()
  print("1.Increase Polarity  (Increase positivity/Decrease negativity) \n2.Decrease Polarity (Increase negativity/Decrease positivity)")
  opt = int(input())
  if opt == 1:
    print("Increasing polarity")
    calculate_sentiment(text, opt)
  elif opt == 2:
    print("Decreasing polarity")
    calculate_sentiment(text, opt)
  else:
    print("Wrong option")

test()

test()